{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT1cLnh1VJyW"
      },
      "outputs": [],
      "source": [
        "# !pip install gpy\n",
        "# !pip install gpyopt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "from scipy.stats import uniform\n",
        "import GPy\n",
        "import GPyOpt\n",
        "from GPyOpt.methods import BayesianOptimization\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "metadata": {
        "id": "NE-sO9XVZdl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_runtime(func):\n",
        "    start_time = time.time()\n",
        "    result = func()\n",
        "    end_time = time.time()\n",
        "    runtime = end_time - start_time\n",
        "    return result, runtime"
      ],
      "metadata": {
        "id": "TyKtihLKZi2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(df):\n",
        "  y = df['logerror']\n",
        "  X = df.drop(columns=['logerror'])\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "ILBcg-VGZq0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_search(X_train, y_train, X_test, y_test, param_range):\n",
        "\n",
        "  random_search_result = {}\n",
        "\n",
        "  xgb = XGBRegressor()\n",
        "\n",
        "  learning_rate_range    = param_range['learning_rate']\n",
        "  gamma_range            = param_range['gamma']\n",
        "  max_depth_range        = param_range['max_depth']\n",
        "  n_estimators_range     = param_range['n_estimators']\n",
        "  min_child_weight_range = param_range['min_child_weight']\n",
        "\n",
        "  param_dist = {\"learning_rate\":    uniform(learning_rate_range[0],    learning_rate_range[1]),\n",
        "                \"gamma\":            uniform(gamma_range[0],            gamma_range[1]),\n",
        "                \"max_depth\":        range(max_depth_range[0],          max_depth_range[1]),\n",
        "                \"n_estimators\":     range(n_estimators_range[0],       n_estimators_range[1]),\n",
        "                \"min_child_weight\": uniform(min_child_weight_range[0], min_child_weight_range[1])}\n",
        "\n",
        "  rs = RandomizedSearchCV(xgb, param_distributions=param_dist,\n",
        "                          scoring='r2', n_iter=25)\n",
        "\n",
        "  _,random_search_result['runtime'] = measure_runtime(lambda: rs.fit(X_train, y_train));\n",
        "\n",
        "  random_search_result['score'] = rs.score(X_test, y_test)\n",
        "\n",
        "  return random_search_result"
      ],
      "metadata": {
        "id": "rIO3Qw8TZrd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization objective\n",
        "def cv_score(params):\n",
        "    params = params[0]\n",
        "    score = cross_val_score(\n",
        "                XGBRegressor(learning_rate     = params[0],\n",
        "                              gamma            = params[1],\n",
        "                              max_depth        = round(params[2]),\n",
        "                              n_estimators     = round(params[3]),\n",
        "                              min_child_weight = params[4]),\n",
        "                X_train, y_train, scoring='r2').mean()\n",
        "    score = np.array(score)\n",
        "    return score"
      ],
      "metadata": {
        "id": "c8CVVyH7Z1qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bayesian_opt(X_train, y_train, X_test, y_test, param_range):\n",
        "\n",
        "  bayesian_opt_result = {}\n",
        "\n",
        "  learning_rate_range    = param_range['learning_rate']\n",
        "  gamma_range            = param_range['gamma']\n",
        "  max_depth_range        = param_range['max_depth']\n",
        "  n_estimators_range     = param_range['n_estimators']\n",
        "  min_child_weight_range = param_range['min_child_weight']\n",
        "\n",
        "  domain = [{'name': 'learning_rate',    'type': 'continuous', 'domain': (learning_rate_range[0],    learning_rate_range[1])},\n",
        "            {'name': 'gamma',            'type': 'continuous', 'domain': (gamma_range[0],            gamma_range[1])},\n",
        "            {'name': 'max_depth',        'type': 'continuous', 'domain': (max_depth_range[0],        max_depth_range[1])},\n",
        "            {'name': 'n_estimators',     'type': 'continuous', 'domain': (n_estimators_range[0],     n_estimators_range[1])},\n",
        "            {'name': 'min_child_weight', 'type': 'continuous', 'domain': (min_child_weight_range[0], min_child_weight_range[1])}]\n",
        "\n",
        "\n",
        "\n",
        "  optimizer = BayesianOptimization(f=cv_score,\n",
        "                                  domain=domain,\n",
        "                                  model_type='GP',\n",
        "                                  acquisition_type ='EI',\n",
        "                                  acquisition_jitter = 0.05,\n",
        "                                  exact_feval=True,\n",
        "                                  maximize=True)\n",
        "\n",
        "  # Only 20 iterations because we have 5 initial random points\n",
        "  _,bayesian_opt_result['runtime'] = measure_runtime(lambda: optimizer.run_optimization(max_iter=20))\n",
        "\n",
        "  best_params_index = (-optimizer.Y).argmax()\n",
        "  best_params = optimizer.X[best_params_index]\n",
        "\n",
        "  best_xgb = XGBRegressor(learning_rate    = best_params[0],\n",
        "                          gamma            = best_params[1],\n",
        "                          max_depth        = round(best_params[2]),\n",
        "                          n_estimators     = round(best_params[3]),\n",
        "                          min_child_weight = best_params[4])\n",
        "\n",
        "  best_xgb.fit(X_train, y_train)\n",
        "  bayesian_opt_result['score'] = best_xgb.score(X_test, y_test)\n",
        "\n",
        "  return bayesian_opt_result\n",
        ""
      ],
      "metadata": {
        "id": "vqzfnihKZ8Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_dataframes = {}\n",
        "\n",
        "pca_dataframes['10%'] = pd.read_csv('pca_10.csv')\n",
        "pca_dataframes['50%'] = pd.read_csv('pca_50.csv')\n",
        "pca_dataframes['75%'] = pd.read_csv('pca_75.csv')\n",
        "\n",
        "umap_dataframes = {}\n",
        "\n",
        "umap_dataframes['10%'] = pd.read_csv('umap_10.csv')\n",
        "umap_dataframes['50%'] = pd.read_csv('umap_50.csv')\n",
        "umap_dataframes['75%'] = pd.read_csv('umap_75.csv')\n",
        "\n",
        "autoencoder_dataframes = {}\n",
        "\n",
        "autoencoder_dataframes['10%'] = pd.read_csv('autoencoder_10.csv')\n",
        "autoencoder_dataframes['50%'] = pd.read_csv('autoencoder_50.csv')\n",
        "autoencoder_dataframes['75%'] = pd.read_csv('autoencoder_75.csv')\n",
        "\n",
        "ikpca_dataframes = {}\n",
        "\n",
        "ikpca_dataframes['10%'] = pd.read_csv('ikpca_10.csv')\n",
        "ikpca_dataframes['50%'] = pd.read_csv('ikpca_50.csv')\n",
        "ikpca_dataframes['75%'] = pd.read_csv('ikpca_75.csv')"
      ],
      "metadata": {
        "id": "-2XT8A6TZ-KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_range = {\"learning_rate\":   [0, 1],\n",
        "              \"gamma\":            [0, 5],\n",
        "              \"max_depth\":        [1, 10],\n",
        "              \"n_estimators\":     [1, 50],\n",
        "              \"min_child_weight\": [1, 10]}"
      ],
      "metadata": {
        "id": "sSWxBMMVaApS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimension_reduction_methods = {}\n",
        "\n",
        "dimension_reduction_methods['pca'] = pca_dataframes\n",
        "dimension_reduction_methods['umap'] = umap_dataframes\n",
        "dimension_reduction_methods['autoencoder'] = autoencoder_dataframes\n",
        "dimension_reduction_methods['ikpca'] = ikpca_dataframes\n",
        "\n",
        "method_results = {}\n",
        "\n",
        "for method, percentages in dimension_reduction_methods.items():\n",
        "\n",
        "  method_results[method] = {}\n",
        "  percentage_results = method_results[method]\n",
        "\n",
        "  for percentage, df in percentages.items():\n",
        "\n",
        "    X_train, y_train, X_test, y_test = split_data(df)\n",
        "\n",
        "    percentage_results[percentage] = {}\n",
        "    percentage_results[percentage]['random_search'] = random_search(X_train, y_train, X_test, y_test, param_range)\n",
        "    percentage_results[percentage]['bayesian_opt'] = bayesian_opt(X_train, y_train, X_test, y_test, param_range)"
      ],
      "metadata": {
        "id": "jiw9vbtlaC-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZsdXrT8laFD4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}