{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT1cLnh1VJyW"
      },
      "outputs": [],
      "source": [
        "!pip install gpy\n",
        "!pip install gpyopt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "from scipy.stats import uniform\n",
        "import GPy\n",
        "import GPyOpt\n",
        "from GPyOpt.methods import BayesianOptimization\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import statistics"
      ],
      "metadata": {
        "id": "NE-sO9XVZdl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_runtime(func):\n",
        "    start_time = time.time()\n",
        "    result = func()\n",
        "    end_time = time.time()\n",
        "    runtime = end_time - start_time\n",
        "    return result, runtime"
      ],
      "metadata": {
        "id": "TyKtihLKZi2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(df):\n",
        "  y = df['logerror']\n",
        "  X = df.drop(columns=['logerror'])\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
        "  return X_train, y_train, X_test, y_test"
      ],
      "metadata": {
        "id": "ILBcg-VGZq0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-parameter Tuning Methods"
      ],
      "metadata": {
        "id": "FPmOk4IFg7rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def random_search(X_train, y_train, X_test, y_test, param_range):\n",
        "\n",
        "  xgb = XGBRegressor()\n",
        "\n",
        "  param_dist = {\"learning_rate\":    uniform(  param_range['learning_rate'][0],    param_range['learning_rate'][1]     ),\n",
        "                \"gamma\":            uniform(  param_range['gamma'][0],            param_range['gamma'][1]             ),\n",
        "                \"max_depth\":        range(    param_range['max_depth'][0],        param_range['max_depth'][1]         ),\n",
        "                \"n_estimators\":     range(    param_range['n_estimators'][0],     param_range['n_estimators'][1]      ),\n",
        "                \"min_child_weight\": uniform(  param_range['min_child_weight'][0], param_range['min_child_weight'][1]  )}\n",
        "\n",
        "  rs = RandomizedSearchCV(xgb, param_distributions=param_dist,\n",
        "                          scoring='r2', n_iter=25)\n",
        "\n",
        "  _,runtime = measure_runtime(lambda: rs.fit(X_train, y_train));\n",
        "\n",
        "  score = rs.score(X_test, y_test)\n",
        "\n",
        "  return runtime, score"
      ],
      "metadata": {
        "id": "rIO3Qw8TZrd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def repeat_random_search(X_train, y_train, X_test, y_test, param_range, iterations):\n",
        "\n",
        "  runtimes = []\n",
        "  scores = []\n",
        "\n",
        "  for i in range(iterations):\n",
        "    runtime, score = random_search(X_train, y_train, X_test, y_test, param_range)\n",
        "    runtimes.append(runtime)\n",
        "    scores.append(score)\n",
        "\n",
        "  result = {}\n",
        "  result['runtimes'] = runtimes\n",
        "  result['scores'] = scores\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "PYlUkV3scAex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bayes_opt(X_train, y_train, X_test, y_test, param_range):\n",
        "\n",
        "\n",
        "  domain = [{'name': 'learning_rate',    'type': 'continuous', 'domain': (param_range['learning_rate'][0],    param_range['learning_rate'][1])},\n",
        "            {'name': 'gamma',            'type': 'continuous', 'domain': (param_range['gamma'][0],            param_range['gamma'][1])},\n",
        "            {'name': 'max_depth',        'type': 'continuous', 'domain': (param_range['max_depth'][0],        param_range['max_depth'][1])},\n",
        "            {'name': 'n_estimators',     'type': 'continuous', 'domain': (param_range['n_estimators'][0],     param_range['n_estimators'][1])},\n",
        "            {'name': 'min_child_weight', 'type': 'continuous', 'domain': (param_range['min_child_weight'][0], param_range['min_child_weight'][1])}]\n",
        "\n",
        "  # Optimization objective\n",
        "  def cv_score(params):\n",
        "      params = params[0]\n",
        "      score = cross_val_score(\n",
        "                  XGBRegressor(learning_rate     = params[0],\n",
        "                                gamma            = params[1],\n",
        "                                max_depth        = round(params[2]),\n",
        "                                n_estimators     = round(params[3]),\n",
        "                                min_child_weight = params[4]),\n",
        "                  X_train, y_train, scoring='r2').mean()\n",
        "      score = np.array(score)\n",
        "      return score\n",
        "\n",
        "  optimizer = BayesianOptimization(f=cv_score,\n",
        "                                  domain=domain,\n",
        "                                  model_type='GP',\n",
        "                                  acquisition_type ='EI',\n",
        "                                  acquisition_jitter = 0.05,\n",
        "                                  exact_feval=True,\n",
        "                                  maximize=True)\n",
        "\n",
        "  # Only 20 iterations because we have 5 initial random points\n",
        "  _,runtime = measure_runtime(lambda: optimizer.run_optimization(max_iter=20))\n",
        "\n",
        "  best_params_index = (-optimizer.Y).argmax()\n",
        "  best_params = optimizer.X[best_params_index]\n",
        "\n",
        "  best_xgb = XGBRegressor(learning_rate    = best_params[0],\n",
        "                          gamma            = best_params[1],\n",
        "                          max_depth        = round(best_params[2]),\n",
        "                          n_estimators     = round(best_params[3]),\n",
        "                          min_child_weight = best_params[4])\n",
        "\n",
        "  best_xgb.fit(X_train, y_train)\n",
        "  score = best_xgb.score(X_test, y_test)\n",
        "\n",
        "  return runtime, score"
      ],
      "metadata": {
        "id": "vqzfnihKZ8Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def repeat_bayes_opt(X_train, y_train, X_test, y_test, param_range, iterations):\n",
        "\n",
        "  runtimes = []\n",
        "  scores = []\n",
        "\n",
        "  for i in range(iterations):\n",
        "    runtime, score = bayes_opt(X_train, y_train, X_test, y_test, param_range)\n",
        "    runtimes.append(runtime)\n",
        "    scores.append(score)\n",
        "\n",
        "  result = {}\n",
        "  result['runtimes'] = runtimes\n",
        "  result['scores'] = scores\n",
        "\n",
        "  return result"
      ],
      "metadata": {
        "id": "HNcKU5hGcGAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "C04MbP58hIef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca_dataframes = {}\n",
        "\n",
        "pca_dataframes['10%'] = pd.read_csv('pca_10.csv')\n",
        "pca_dataframes['50%'] = pd.read_csv('pca_50.csv')\n",
        "pca_dataframes['75%'] = pd.read_csv('pca_75.csv')\n",
        "\n",
        "umap_dataframes = {}\n",
        "\n",
        "umap_dataframes['10%'] = pd.read_csv('umap_10.csv')\n",
        "umap_dataframes['50%'] = pd.read_csv('umap_50.csv')\n",
        "umap_dataframes['75%'] = pd.read_csv('umap_75.csv')\n",
        "\n",
        "autoencoder_dataframes = {}\n",
        "\n",
        "autoencoder_dataframes['10%'] = pd.read_csv('autoencoder_10.csv')\n",
        "autoencoder_dataframes['50%'] = pd.read_csv('autoencoder_50.csv')\n",
        "autoencoder_dataframes['75%'] = pd.read_csv('autoencoder_75.csv')\n",
        "\n",
        "ikpca_dataframes = {}\n",
        "\n",
        "ikpca_dataframes['10%'] = pd.read_csv('ikpca_10.csv')\n",
        "ikpca_dataframes['50%'] = pd.read_csv('ikpca_50.csv')\n",
        "ikpca_dataframes['75%'] = pd.read_csv('ikpca_75.csv')"
      ],
      "metadata": {
        "id": "-2XT8A6TZ-KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimension_reduced_data = {}\n",
        "\n",
        "dimension_reduced_data['PCA'] = pca_dataframes\n",
        "dimension_reduced_data['UMAP'] = umap_dataframes\n",
        "dimension_reduced_data['Autoencoder'] = autoencoder_dataframes\n",
        "dimension_reduced_data['IKPCA'] = ikpca_dataframes"
      ],
      "metadata": {
        "id": "Kwn7ZGrYdE-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_range = {\"learning_rate\":   [0, 1],\n",
        "              \"gamma\":            [0, 5],\n",
        "              \"max_depth\":        [1, 10],\n",
        "              \"n_estimators\":     [1, 50],\n",
        "              \"min_child_weight\": [1, 10]}"
      ],
      "metadata": {
        "id": "sSWxBMMVaApS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Models"
      ],
      "metadata": {
        "id": "OWZ0N1_MhUcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#runs for hours\n",
        "\n",
        "xgboost_results = {}\n",
        "\n",
        "for reduction_method, percentages in dimension_reduced_data.items():\n",
        "\n",
        "  xgboost_results[reduction_method] = {}\n",
        "  percentage_results = xgboost_results[reduction_method]\n",
        "\n",
        "  for percentage, df in percentages.items():\n",
        "\n",
        "    X_train, y_train, X_test, y_test = split_data(df)\n",
        "\n",
        "    percentage_results[percentage] = {}\n",
        "    percentage_results[percentage]['random'] = repeat_random_search(X_train, y_train, X_test, y_test, param_range, 10)\n",
        "    percentage_results[percentage]['bayes'] = repeat_bayes_opt(X_train, y_train, X_test, y_test, param_range, 10)"
      ],
      "metadata": {
        "id": "jiw9vbtlaC-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_results = {}\n",
        "\n",
        "for reduction_method, percentages in dimension_reduced_data.items():\n",
        "\n",
        "  linear_results[reduction_method] = {}\n",
        "  percentage_results = linear_results[reduction_method]\n",
        "\n",
        "  for percentage, df in percentages.items():\n",
        "\n",
        "    X_train, y_train, X_test, y_test = split_data(df)\n",
        "\n",
        "    reg = LinearRegression()\n",
        "\n",
        "    percentage_results[percentage] = {}\n",
        "    _,percentage_results[percentage]['runtimes'] = measure_runtime(lambda: reg.fit(X_train, y_train))\n",
        "    percentage_results[percentage]['scores'] = reg.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "ZsdXrT8laFD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Results"
      ],
      "metadata": {
        "id": "5i3q2OZMhalV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_bars(x_linear, x_random, x_bayes, y_linear, y_random, y_bayes, y_type):\n",
        "\n",
        "  for i in range(len(y_linear)):\n",
        "\n",
        "    linear_va = 'top' if y_linear[i] < 0 else 'bottom'\n",
        "    random_va = 'top' if y_random[i] < 0 else 'bottom'\n",
        "    bayes_va = 'top' if y_bayes[i] < 0 else 'bottom'\n",
        "\n",
        "    if y_type == 'scores':\n",
        "      plt.text(x_linear[i], y_linear[i], f'{y_linear[i]:.2e}', ha='center', va=linear_va)\n",
        "      plt.text(x_random[i], y_random[i], f'{y_random[i]:.2e}', ha='center', va=random_va)\n",
        "      plt.text(x_bayes[i], y_bayes[i], f'{y_bayes[i]:.2e}', ha='center', va=bayes_va)\n",
        "    else:\n",
        "      plt.text(x_linear[i], y_linear[i], f'{y_linear[i]:.2f}', ha='center', va=linear_va)\n",
        "      plt.text(x_random[i], y_random[i], f'{y_random[i]:.2f}', ha='center', va=random_va)\n",
        "      plt.text(x_bayes[i], y_bayes[i], f'{y_bayes[i]:.2f}', ha='center', va=bayes_va)"
      ],
      "metadata": {
        "id": "RmsU7GQPWs4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_reduction_method(reduction_method, y_type):\n",
        "\n",
        "  percentages = ['10%', '50%', '75%']\n",
        "\n",
        "  y_linear = []\n",
        "  y_linear.append(linear_results[reduction_method]['10%'][y_type])\n",
        "  y_linear.append(linear_results[reduction_method]['50%'][y_type])\n",
        "  y_linear.append(linear_results[reduction_method]['75%'][y_type])\n",
        "\n",
        "\n",
        "  y_random = []\n",
        "  y_random.append(statistics.mean(xgboost_results[reduction_method]['10%']['random'][y_type]))\n",
        "  y_random.append(statistics.mean(xgboost_results[reduction_method]['50%']['random'][y_type]))\n",
        "  y_random.append(statistics.mean(xgboost_results[reduction_method]['75%']['random'][y_type]))\n",
        "\n",
        "  y_bayes = []\n",
        "  y_bayes.append(statistics.mean(xgboost_results[reduction_method]['10%']['bayes'][y_type]))\n",
        "  y_bayes.append(statistics.mean(xgboost_results[reduction_method]['50%']['bayes'][y_type]))\n",
        "  y_bayes.append(statistics.mean(xgboost_results[reduction_method]['75%']['bayes'][y_type]))\n",
        "\n",
        "  # Set the positions for the bars\n",
        "  positions = np.arange(0, len(percentages)*3, 3)\n",
        "\n",
        "  bar_width = 0.8\n",
        "\n",
        "  x_linear = positions - bar_width\n",
        "  x_random = positions\n",
        "  x_bayes = positions + bar_width\n",
        "\n",
        "  # grouped bar chart\n",
        "  plt.bar(x_linear, y_linear, bar_width, label='Linear Regression', color='lightgreen')\n",
        "  plt.bar(x_random, y_random, bar_width, label='XGBoost Random Search', color='orange')\n",
        "  plt.bar(x_bayes, y_bayes, bar_width, label='XGBoost Bayesian Optimization', color='skyblue')\n",
        "\n",
        "  plt.axhline(y=0, color='gray', linestyle='--')\n",
        "\n",
        "\n",
        "  plt.xlabel('Percentage of Original Dimensions')\n",
        "\n",
        "  ylabel = 'Average R-squared' if y_type == 'scores' else 'Average Runtime (s)'\n",
        "  plt.ylabel(ylabel)\n",
        "\n",
        "\n",
        "  plt.xticks(positions, percentages)\n",
        "\n",
        "  plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
        "\n",
        "  # Add text label above each bar\n",
        "  label_bars(x_linear, x_random, x_bayes, y_linear, y_random, y_bayes, y_type)\n",
        "\n",
        "\n",
        "  plt.title(reduction_method + \" \" + y_type.capitalize())\n",
        "\n",
        "  plt.gcf().set_size_inches(9, 6)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "d5a_c5z4cwem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_reduction_method('PCA', 'scores')\n",
        "plot_reduction_method('UMAP', 'scores')\n",
        "plot_reduction_method('Autoencoder', 'scores')\n",
        "plot_reduction_method('IKPCA', 'scores')"
      ],
      "metadata": {
        "id": "XQqHhF9FeE_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_reduction_method('PCA', 'runtimes')\n",
        "plot_reduction_method('UMAP', 'runtimes')\n",
        "plot_reduction_method('Autoencoder', 'runtimes')\n",
        "plot_reduction_method('IKPCA', 'runtimes')"
      ],
      "metadata": {
        "id": "QaQu5aMqeN_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}